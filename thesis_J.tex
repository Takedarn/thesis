\documentclass[12pt,a4j]{jreport}
\usepackage[dvipdfmx]{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{float}
\usepackage{lscape}
\renewcommand{\bibname}{参考文献}
\begin{document}
	\thispagestyle{empty}
\begin{center}
修士論文\\% どちらか一方を消してください．
\vfill
推論における重要度単語を転移させる知識蒸留法\\\
\vfill
武田 遥暉\\
\vfill
主指導教員  白井 清昭\\
\vfill
北陸先端科学技術大学院大学\\
先端科学技術研究科\\
（情報科学）\\ %取得希望学位
\vfill
令和8年3月\\ % 学位授与年月
\vfill
\end{center}
\newpage
\pagestyle{empty}
\centerline{Abstract}
English abstract (1200 words)\\
〇〇〇〇〇〇〇〇〇〇〇〇〇〇〇〇〇〇〇
\clearpage
\centerline{概要}
日本語の概要\\
〇〇〇〇〇〇〇〇〇〇〇〇〇〇〇〇〇〇〇

\clearpage\setcounter{page}{0}\pagenumbering{roman}\pagestyle{plain}
\tableofcontents
\listoffigures
\listoftables
\clearpage\setcounter{page}{0}\pagenumbering{arabic}

\chapter{はじめに}

\section{背景}
大規模言語モデル（Large Language Model; LLM）は、大規模テキストで事前学習された言語モデルであり、文脈情報を高次元表現として獲得することでさまざまな言語タスクにおいて高い性能を示している。特に分類モデルとして用いる場合、入力文全体の意味情報を統合した表現を利用することで、文書分類や感情分析などにおいて高い性能を発揮する。

このような能力を実現するため近年のLLMは大規模なモデルサイズを有しており、その運用には多数のGPUをはじめとする計算機資源を必要とする。その結果、十分な資金力を持つ一部の組織のみが利用可能である点や、クラウド経由でGPU資源にアクセスできない環境では導入が困難である点が、実社会への幅広い展開を妨げる課題となっている。

そのため、LLMを教師モデル、より少ないパラメータを持つモデルを生徒モデルとし、教師モデルの性能を可能な限り維持しながら、タスク遂行能力を生徒モデルへ転移する手法として知識蒸留が提案されている。特に分類タスクにおいては、性能をほぼ維持したままモデルサイズを半分程度まで削減可能であるなど、高い有効性が示されており知識蒸留はモデル軽量化の代表的な手法として確立している。

しかしながら、知識蒸留は、計算資源の制約下において教師モデルの代替として利用可能な生徒モデルを構築することを目的とした技術であるにもかかわらず、蒸留によって学習された生徒モデルは分類精度を維持できている一方、推論時に重要と判断する単語が教師モデルと一致しないことが報告されている。\cite{rai2025compressedmodelstrustequivalentlarge}このような差異は、医療分野や金融分野など判断根拠の信頼性が重視される領域において致命的な問題となり得るため、生徒モデルを教師モデルの単純な代替として用いることには依然として課題が残っている。

\section{目的}
本研究では、教師モデルと同じ単語に注目して生徒モデルが推論を行うよう学習させることを目的とする。対象タスクに対して十分に学習された教師モデルを用意し、以下の手順に従って知識蒸留を適用する。

まず、目的のタスクに対し十分にファインチューニングされた教師モデルと、教師モデルよりも小規模な未学習の生徒モデルを準備し、両モデルに同一の入力インスタンスを与えて推論を行う。次に、得られた推論結果に対してIntegrated Gradientsを用いて単語重要度を算出し、それらを重要度分布として表現する。最後に、教師モデルと生徒モデルの重要度分布が近づくよう損失関数を設計し、先行研究で提案されている知識蒸留手法に当該損失項を導入することで、生徒モデルの学習を行う。本手法により、分類精度を先行研究と同程度に維持したまま、推論時に重要と判断される単語に関して教師モデルとの整合性を向上させることを狙う。

\section{本論文の構成}
本論文の構成は以下の通りである。2章では先行研究について述べる。3章では提案手法について詳細に説明する。4章では提案手法の評価実験について述べる。最後に5章では、本研究の手法についてのまとめと今後の課題について述べる。

\chapter{関連研究}
本章では本研究の関連研究について述べる。本章で述べる研究トピックはKnowledge Distillation（以下、知識蒸留）\cite{hinton2015distillingknowledgeneuralnetwork}である。知識蒸留は、性能が高くパラメータ数も大きいモデルを教師モデルとし、パラメータ数が小さいモデルへとタスクを解くための能力を転移されるための代表的な技術である。これまでに様々な知識蒸留手法が提案されてきており、教師モデルの出力層の知識を転移するものや、隠れ状態からの知識も転移させるもの、両方から知識を転移させるもの等、様々なパターンの知識蒸留のアプローチが提案されてきた。

また、分類モデルの知識蒸留における教師モデルとしてBERT\cite{devlin-etal-2019-bert}を用いられることが多い。BERTを教師モデルにして、知識蒸留されたモデルの代表的なものとしてTinyBERT\cite{jiao-etal-2020-tinybert}が存在する。

これらの言語モデルの推論根拠を提供する技術としてIntegrated Gradient\cite{sundararajan2017axiomaticattributiondeepnetworks}がある。Integrated Gradientsは画像処理分野で提案されたものではあるが本研究ではモデルが重要であると認識した単語を抽出するために利用する。

以下、\ref{kd-fundamental}節では、知識蒸留の原理的な設計について述べる。\ref{bert-model}節では、教師モデルとして用いるBERTについて紹介する。\ref{tinybert-model}節では、知識蒸留によって構築された代表的なモデルであるTinyBERTについて述べる。\ref{integrated-gradient}節ではモデルが推論する際の根拠を提示する技術としてIntegrated Gradientsを紹介する。最後に、\ref{methodlogy-characteristic}では、本研究の特色について述べる。

\section{知識蒸留}
\label{kd-fundamental}

知識蒸留（Knowledge Distillation）は、高性能である一方、パラメータ数が多い教師モデルから、
より小規模な生徒モデルへ特定のタスクを解く能力を転移させるための代表的な技術である。
一般に、教師モデルは対象タスクに対して十分に学習（ファインチューニング）されており、
生徒モデルは教師モデルの振る舞いを模倣することで効率的な学習を行う。

分類タスクでは、通常、あるドメインに対して数百から数万のラベル付きインスタンスが与えられる。
代表的な自然言語理解ベンチマークであるGLUE\cite{wang-etal-2018-glue}は、
複数の分類タスクから構成されるデータセット群であり、
知識蒸留の評価においても標準的に用いられる。
GLUEに含まれるMRPC（Microsoft Research Paraphrase Corpus）は、
2つの英文が意味的に等価であるかどうかを判定する二値分類タスクである。
各インスタンスにはラベル $y \in \{0,1\}$ が付与されており、
意味的に等価な場合を1、そうでない場合を0と定義する。

\begin{quote}
例\\
sentence1: Amrozi accused his brother, whom he called ``the witness'', of deliberately distorting his evidence.\\
sentence2: Referring to him as only ``the witness'', Amrozi accused his brother of deliberately distorting his evidence.\\
label: equivalent (1)
\end{quote}

通常の分類モデルの学習では、
生徒モデル $f_s$ が入力 $x$ に対して予測するクラス確率分布
$p_s(y \mid x)$ と、
正解ラベル $y$ との間のクロスエントロピー損失を最小化する。
この損失関数は、次式で定義される。
\begin{equation}
\mathcal{L}_{\mathrm{CE}}
= - \sum_{c} y_c \log p_s(c \mid x)
\label{eq:ce}
\end{equation}
ここで、$c$ はクラスを表し、
$y_c$ は正解クラスに対応するワンホット表現である。

知識蒸留では、
この正解ラベルに基づく学習に加えて、
同一の入力 $x$ に対する教師モデル $f_t$ の出力分布
$p_t(y \mid x)$ を、
生徒モデルが模倣することを目的とする。
教師モデルと生徒モデルの出力分布の乖離を測る指標として、
Kullback--Leibler（KL）ダイバージェンスが一般に用いられる。
このとき、知識蒸留損失は、次式で表される。
\begin{equation}
\mathcal{L}_{\mathrm{KD}}
= \mathrm{KL}\bigl(
p_t(\cdot \mid x)
\,\|\, 
p_s(\cdot \mid x)
\bigr)
\label{eq:kd}
\end{equation}
ここで、$\cdot$ はクラス全体を表し、
教師モデルが出力する確率分布全体を、
生徒モデルが近似することを意味する。

最終的な学習では、
正解ラベルに基づくクロスエントロピー損失と、
教師モデルの振る舞いを模倣する知識蒸留損失を組み合わせた、
次の損失関数を最小化する。
\begin{equation}
\mathcal{L}
= (1-\lambda)\mathcal{L}_{\mathrm{CE}}
\quad+\quad \lambda \mathcal{L}_{\mathrm{KD}}
\label{eq:total}
\end{equation}
ここで、$\lambda \in [0,1]$ はハイパーパラメータであり、
正解ラベルと教師モデルの知識のどちらを重視するかを制御する。

このように知識蒸留では、
データセットに明示的に含まれるラベル情報だけでなく、
教師モデルが獲得した予測分布という暗黙的な知識を
生徒モデルに転移することで、
高い性能を維持したままモデルの軽量化を実現することを目的としている。

\section{事前学習済み言語モデル}
\subsection{事前学習済みモデル}
\label{bert-model}

BERT\cite{devlin-etal-2019-bert}は、Transformer\cite{vaswani2023attentionneed}を基盤とした双方向言語モデルであり、大規模コーパスを用いた事前学習によって汎用的な言語表現を獲得する。BERTの事前学習では、Masked Language Model（MLM）と Next Sentence Prediction（NSP）の2つのタスクが用いられる。

MLMでは、入力文中の一部の単語をマスクし、その単語を周辺文脈から予測することで単語表現を学習する。MLMの損失関数は以下のように定義される。
\begin{equation}
\mathcal{L}_{\mathrm{MLM}}
= - \sum_{i=1}^{N} \log p(t_i \mid T_i)
\label{eq:mlm}
\end{equation}
ここで、$t_i$ はマスクされた単語、$T_i$ は $Ft_i$ 以外の単語からなる入力文を表す。

次に、NSP（Next Sentence Prediction）は、2つの文が元の文書中で連続しているか否かを判定する二値分類タスクであり、文間の関係性を学習することを目的としている。事前学習時には、文書中で実際に連続する文の組を正例（$y=1$）、無関係な文の組を負例（$y=0$）として与える。

BERTでは、入力文対全体を表す \texttt{[CLS]} トークンの最終層表現を用いて、2文が連続している確率 $P_{\mathrm{NSP}}$ を推定する。NSPの損失関数は、二値交差エントロピー損失として次式で定義される。
\begin{equation}
\mathcal{L}_{\mathrm{NSP}}
= - \left[
y \log P_{\mathrm{NSP}}
+ (1 - y) \log (1 - P_{\mathrm{NSP}})
\right]
\label{eq:nsp}
\end{equation}
ここで、$y \in \{0,1\}$ は2文が連続しているか否かを示す正解ラベルであり、$P_{\mathrm{NSP}}$ はモデルによって推定された連続確率を表す。

このようにNSPを導入することで、BERTは単語レベルの意味情報だけでなく、文脈の整合性を捉えた表現を獲得することが可能となる。


\subsection{本研究における教師モデルとしてのBERT}
本研究では教師モデルとして、BERTを用いる。BERTは事前学習によって大規模コーパスでの事前学習により汎用的な言語表現を獲得しており、このモデルに全結合層を追加し、対象タスクに対してファインチューニングを行うことで高い性能を獲得できる。本研究では。GLUE内の8つの分類タスクに対してファインチューニングを行い、各タスクに対して十分に学習されたBERTモデルを教師モデルとして用いる。
\section{知識蒸留によって構築されたモデル}
知識蒸留が提案されて以来、様々な手法が提案されてきた。初期は、前結合層に対し知識を転移されてきたが、Transformerベースのモデルが提案されて以来、全結合層だけでなく事前学習においても知識蒸留が適用されるようになった。知識蒸留で代表的なものとしてはDistilBERT\cite{sanh2019distilbert}が存在する。DistilBERTは、ファインチューニングの段階における知識蒸留の適用だけでなく事前学習済みのBERTを教師モデルとしての内部表現や出力挙動を模倣する生徒モデルとして訓練される。その後、ファインチューニング時にも知識蒸留が適用することで、BERTのパラメータ数を約40\%削減しながらも、下流タスクにおいて高い性能を維持することに成功している。

TinyBERT\cite{jiao-etal-2020-tinybert}は、BERTを教師モデルとして知識蒸留を適用することで構築された軽量な言語モデルである。TinyBERTは、教師モデルの出力層だけでなく、中間層の隠れ状態やAttention機構の重みも模倣することで、モデルサイズを大幅に削減しながら高い性能を維持することに成功している。

\subsubsection{データ拡張 (data augmentation)}
学習においてTinyBERTは下流タスクでの蒸留効果を高めるためにデータ拡張を併用することが知られている。具体的には、元のデータセットに対してランダムに単語を挿入・削除・置換することで多様な入力インスタンスを生成し、頑健性を向上させる。

\subsubsection{学習の流れ}
TinyBERTの蒸留は大きく2段階で行われる。

\paragraph{事前学習段階 (pre-training)}
事前学習段階では、BERTの事前学習で用いられたMasked Language Model（MLM）やNext Sentence Prediction（NSP）に加えて、中間層の隠れ状態やAttention重みの模倣を目的とした損失を導入する。これにより、生徒モデルは教師の内部表現を効率的に学習し、下流タスクへの基盤を構築する。

\paragraph{下流タスクのファインチューニング (downstream fine-tuning)}
下流タスクへの適応はさらに2段階（段階的蒸留）で実施される。

\begin{description}
	\setlength{\itemsep}{0.8\baselineskip}
	\item[第1段階 — 中間層蒸留 (intermediate layer distillation)]
	まず中間層の隠れ状態やAttention重みの模倣損失を導入し、生徒の内部表現を教師に近づけることで下流タスクへの適応準備を行う。

	\item[第2段階 — 出力層蒸留 (prediction layer distillation)]
	続いて教師の出力（ソフトラベル）とデータのハードラベルを併用して生徒の出力層を学習させ、教師モデルの推論能力を模倣させる。
\end{description}

TinyBERTはこの学習の流れを通じてBERTの知識を効率的に圧縮し、軽量ながら高性能なモデルを実現している。

\clearpage
\section{モデルの推論根拠の解釈に関する研究}
\label{model-explain}
\subsection{Integrated Gradient}
\label{integrated-gradient}

近年、深層学習モデルは画像認識や自然言語処理などの多くのタスクにおいて人間を凌駕する性能を達成している。しかし、その高い性能の代償として、モデル内部の計算プロセスは複雑化し、人間にとって理解困難な「ブラックボックス」となっていることで、モデルの推論における根拠となる特徴量を明示的に把握することが難しいという課題が存在する。

この要求に応えるための技術として、特徴量帰属法（Feature Attribution）が研究されている。特徴量帰属法は、モデルの予測結果に対する入力特徴量（例えば、画像の各ピクセルやテキストの各単語）の寄与度を定量的に算出する手法の総称である。寄与度が高い特徴量は、モデルが予測を行う上で重要な手がかりとして利用したことを示唆する。

Integrated Gradients は、ある入力 $x$ と、情報を持たない参照点であるベースライン $x'$ との間の経路に沿って勾配を積分することで定義される。
入力ベクトル $x \in \mathbb{R}^n$ における $i$ 番目の特徴量 $x_i$ の寄与度 $\mathrm{IG}_i(x)$ は以下の式で計算される。

\begin{equation}
\mathrm{IG}_i(x) = (x_i - x'_i) \int_{\alpha=0}^{1} \frac{\partial F(x' + \alpha(x - x'))}{\partial x_i} \, d\alpha
\end{equation}

ここで、$F$ は微分可能な機械学習モデル（例えばニューラルネットワークのソフトマックス出力値）、$x'$ はベースラインベクトルを表す。$\alpha$ は補間係数であり、$[0,1]$ の範囲で変化することで、ベースライン $x'$ から入力 $x$ への直線経路を辿る。この経路積分により、IGは以下の重要な公理的性質を満たす。

\paragraph{感度 (Sensitivity)}
モデルの予測に変化を与える全ての特徴量は、非ゼロの寄与度を持つべきであるという性質である。
従来の単純な勾配法（Simple Gradients）では、ReLUやSigmoidなどの活性化関数が飽和領域（勾配がほぼ0になる領域）に入ると、入力が変化しても勾配が消失し、寄与度が0と計算されてしまう問題があった。これを「勾配消失の問題」と呼ぶ。IGは、ベースラインから入力までの経路全体の勾配を積分するため、途中で勾配が存在すればその影響を捉えることができ、この感度の公理を満たすことができる。

\paragraph{完全性 (Completeness)}
各次元 $i$ における IG の総和は、常に入力 $x$ に対するモデル出力値とベースライン $x'$ に対するモデル出力値の差分に一致する。

\begin{equation}
\sum_{i=1}^n \mathrm{IG}_i(x) = F(x) - F(x')
\end{equation}

この性質は、算出された寄与度の合計がモデルの予測の変化分を過不足なく説明することを保証するものであり、説明の信頼性を担保する上で極めて重要である。

Integrated Gradients は入力変数が連続的に変化し、微分可能であることを前提とした手法である。しかし、自然言語処理で扱うテキストデータは離散的な「単語（トークン）」の列であり、入力値を微小に変化させて勾配を求めるという操作を直接行うことができない。そこでNLPタスクにおいては、単語を連続的なベクトル表現に変換する「埋め込み層（Embedding Layer）」の値を入力とみなしてIGを適用する方法が一般的に用いられる。

ある特定の単語 $w_t$ の寄与度を計算するためには、まずその単語に対応する埋め込みベクトルの各次元 $j$ についてのIG値 $\mathrm{IG}_{t,j}$ を計算する。

\begin{equation}
\mathrm{IG}_{t,j} = (e_{t,j} - b_{t,j}) \int_{\alpha=0}^{1} \frac{\partial F(B + \alpha(E - B))}{\partial e_{t,j}} \, d\alpha
\end{equation}

ここで、$E$ は入力文全体の埋め込み行列、$B$ はベースライン行列である。この式は、ベースラインの埋め込みから入力の埋め込みへと徐々に特徴を変化させながら、モデルの予測値の変化に対する勾配を累積していることを意味する。

最終的に、単語 $w_t$ としての重要度スコア $S_t$ を得るためには、埋め込みベクトルの各次元のIG値を集約する必要がある。集約方法としては、各次元の総和をとる方法や、L2ノルムをとる方法などが用いられる。

このようにして算出されたスコア $S_t$ が大きい単語ほど、モデルの予測判断に強く影響を与えた「重要な単語」であると解釈できる。

IGの計算には積分計算が必要であるが、コンピュータ上での実装においては、有限個のステップによるリーマン和近似が用いられる。積分区間 $[0,1]$ を $m$ 個のステップに分割した場合の近似式は以下のようになる。

\begin{equation}
\mathrm{IG}_i(x) \approx (x_i - x'_i) \frac{1}{m} \sum_{k=1}^{m} \frac{\partial F(x' + \frac{k}{m}(x - x'))}{\partial x_i}
\label{eq:ig}
\end{equation}

ここで、$m$ は近似のステップ数である。各ステップ $k$ においてモデルの逆伝搬計算を行う必要があるため、IGの計算コストはステップ数 $m$ に比例して増大する。
ステップ数が少なすぎると積分の近似誤差が大きくなり、積分誤差が大きくなる。一方でステップ数を多くすれば精度は向上するが、推論時間の数十倍から数百倍の計算時間を要することになる。
したがって、実用上は計算コストと精度のトレードオフを考慮し、近似誤差が計算時間の許容範囲内に収まるような適切なステップ数を設定する必要がある。

\section{本研究の特徴}
\label{methodlogy-characteristic}
従来の知識蒸留手法は、教師と生徒のモデル出力（ロジット）の確率分布を一致させることを目的としてきた。
これに対し、本研究は個々の単語がモデルの最終的な予測判断にどの程度貢献したのかを示すトークン重要度分布に焦点を当てる。Integrated Gradientsを用いてトークン重要度を定量化し、教師モデルと生徒モデルが同じ単語に注目して予測を行うよう学習させることで、「モデルの推論根拠」を明示的に転移させ、精度だけでなく信頼性と解釈可能性を備えた知識蒸留を実現する。

提案手法により、学習後の生徒モデルがどの単語に基づいて予測を行ったかが明らかになる。
教師と生徒のトークン重要度分布を合わせることで、両者の推論プロセスがより透明になり、推論プロセスが重視される領域に対して知識蒸留モデルの代替としての信頼性を向上させる。
\chapter{提案手法}
\section{概要}
本研究では、GLUEに含まれるタスクを対象し、生徒モデルを学習する際に教師モデルと同じ単語に注目するように推論するための損失項を提案する。

提案手法の概要を図\ref{fig:cola_jaccard}に示す。本提案手法は図中のStep 1とStep 2の2段階で構成される。

Step 1では、教師モデルと生徒モデルの双方に同一の学習データを入力し、推論結果に対してIntegrated Gradientsを適用することで各単語の重要度スコアを算出する。これにより、それぞれのモデルが入力文中のどの単語を推論の根拠として重要視しているかを表す重要度分布を作成する。

Step 2では、Step 1で得られた2つの重要度分布間の整合性を高めるための損失関数を定義する。この損失を最小化するように生徒モデルを学習させることで、生徒モデルは教師モデルと同様の単語に注目して推論を行うようにすることを狙う。
\begin{figure}[H]
\centering
\IfFileExists{data/graph/method_overview.png}{\includegraphics[width=\textwidth]{data/graph/method_overview.png}}{%
\fbox{\parbox{\textwidth}{\centering Missing image: data/graph/method\_overview.png}}%
}
\caption{提案手法の概要}\label{fig:cola_jaccard}
\end{figure}

本研究で提案する損失項は、提案されてきた知識蒸留手法に追加で組み込むことができる。本研究における実験については、目的とするタスクでファインチューニングされていたBERTを教師モデルとして採用し、TinyBERTの学習手法に本提案手法を組み込むことで生徒モデルの学習を行う。
\section{重要度分布の作成}
\subsection{Integrated Gradientsによる単語重要度の算出}
本提案において、教師モデルと生徒モデルの重要度分布を作成する手順について述べる。具体的には学習の過程において学習データ1インスタンス毎に教師モデルと生徒モデルに対しIntegrated Gradientsを適用し、そのインスタンスのトークン長分個数の重要度スコアを算出する。GLUE/SST-2タスクにおけるインスタンスの例を以下に示す。SST-2タスクは、与えられた英文が肯定的か否定的かを判定する二値分類タスクである。括弧の中はモデルが予測すべきラベルに対応する。

\begin{quote}
例\\
sentence: seem weird and distanced\\
label: negative (0)
\end{quote}

このインスタンに対し、モデルは予測に際してトークンに分割をする。Integrated Gradientsを適用する際には、トークン毎に重要度スコアが算出される。上記の例に対し、モデルが以下のようなトークン分割を行ったとする。

\begin{quote}
トークン列: [CLS] seem weird and distance \#\#d [SEP]
\end{quote}

[CLS]と[SEP]は特殊トークンであり、トークナイザによって付加される。\#\#dはサブワードである。サブワードとは、単語をさらに細かく分割したものであり、BERTのトークナイザでは未知語に対してサブワード分割が行われる。上記の例では、distancedがdistanceと\#\#dに分割されている。分割された各トークンに対し、式\eqref{eq:ig}によるIntegrated Gradientsを適用することで、各トークン毎に重要度スコアが算出される。

Integrated Gradientsは埋め込みベクトルの各次元に対して計算される。最終的に、各トークンの重要度スコアは埋め込みベクトルの各次元のIG値を集約することで得られる。具体的には、BERTの埋め込みベクトルは768次元であるため、各トークンに対して768個のIG値が算出される。これらを集約することで、各トークンに対する1つの重要度スコアが得られる。

具体的に本研究で用いるSST-2でファインチューニングされたBERTモデルに対し、SST-2のあるインスタンスに対してIntegrated Gradientsを適用した際の各トークンの重要度スコアを示す。

\begin{figure}[H]
\centering
\IfFileExists{data/graph/method_ig_scores.png}{\includegraphics[width=\textwidth]{data/graph/method_ig_scores.png}}{%
\fbox{\parbox{\textwidth}{\centering Missing image: data/graph/method\_ig\_scores.png}}%
}
\caption{Integrated Gradientsによって算出された重要度スコア}\label{fig:method_ig_scores}
\end{figure}

以上のようにして、教師モデルと生徒モデルの双方に対し、学習データ1インスタンス毎にIntegrated Gradientsを適用し、各トークンの重要度スコアを算出する。算出されたIGスコアを集約する方法については、本研究ではL2ノルムを用いる。

学習データセット内のインスタンス $n$ における、トークン $t$ の重要度スコア $S_{n,t}$ は、以下の式で算出される。

\begin{equation}
S_{n,t} = \|\mathbf{IG}_{n,t}\|_2
\label{eq:l2norm}
\end{equation}

ここで、$\mathbf{IG}_{n,t}$ はインスタンス $n$ のトークン $t$ における埋め込みベクトルの各次元に対するIntegrated Gradientsの値をまとめたベクトルを表す。BERTでは埋め込みベクトルの次元数が $d=768$ であるため、$\mathbf{IG}_{n,t} \in \mathbb{R}^{768}$ となる。これにより、各トークンの重要度を単一のスカラー値として表現でき、トークン間の重要度比較が可能になる。本研究では、教師モデルおよび生徒モデルに対して、学習データセット内の各インスタンスごとにIntegrated Gradientsを適用し、各トークンの重要度スコアを算出する。

\subsection{重要度分布の作成}

前節で算出した各トークンの重要度スコアを用いて、教師モデルと生徒モデルの重要度分布を作成する。重要度スコア $S_{n,t}$ は各トークンがモデルの予測に与える影響の大きさを表す非負のスカラー値である。本研究では、この重要度スコアをそのまま用いるのではなく、確率分布に変換してから教師モデルと生徒モデルの比較を行う。

Integrated Gradientsによって算出される重要度スコアの値の範囲は、インスタンスごとに大きく異なる可能性がある。絶対値では大きく異なっても、各インスタンス内での相対的な重要性は類似している場合がある。しかし、重要度スコアの絶対値をそのまま用いると、この相対的な類似性を正しく捉えることができない。

この問題を解決するため、重要度スコアを確率分布に変換する。確率分布への変換では、各インスタンス内でのトークンの重要度スコアを正規化し、全トークンの確率の合計が1になるように調整する。これにより、重要度スコアの絶対的なスケールに依存せず、「各インスタンス内でどのトークンがどの程度重要か」という相対的な情報のみを表現できる。確率分布として表現することで、異なるスケールで算出された重要度スコアを統一的に扱い、教師モデルと生徒モデルの注目パターンを公平に比較できるようになる。

\clearpage
\textbf{(1) 温度スケーリング}

インスタンス $n$ のトークン $t$ における重要度スコア $S_{n,t}$ を温度パラメータ $\tau$ で除算する。

\begin{equation}
s_{n,t} = \frac{S_{n,t}}{\tau}
\label{eq:temperature_scaling}
\end{equation}

温度パラメータ $\tau$ は、重要度分布の鋭さを制御するハイパーパラメータである。$\tau > 1$ の場合、分布は平滑化され、より均一な確率分布に近づく。これにより、重要度が中程度のトークンにも適度な確率質量が割り当てられる。一方、$\tau < 1$ の場合、分布は鋭くなり、重要度が高いトークンへの確率集中が強調される。$\tau = 1$ の場合は、スケーリングを行わず、元の重要度スコアをそのまま用いることに相当する。本研究では、教師モデルと生徒モデルの重要度分布の比較において、いくつかの設定を試した結果、タスクによって温度を調整することが有効であると判断した。

\textbf{(2) ソフトマックス正規化}

次に、スケーリング後のスコアをソフトマックス関数で正規化し、確率分布に変換する。教師モデルの重要度分布 $p^T_{n,t}$ は以下の式で得られる：

\begin{equation}
p^T_{n,t} = \frac{\exp(s^T_{n,t})}{\sum_{t'=1}^{L} \exp(s^T_{n,t'})}
\label{eq:softmax_teacher}
\end{equation}

同様に、生徒モデルの重要度分布 $p^S_{n,t}$ は以下の式で得られる：

\begin{equation}
p^S_{n,t} = \frac{\exp(s^S_{n,t})}{\sum_{t'=1}^{L} \exp(s^S_{n,t'})}
\label{eq:softmax_student}
\end{equation}

ここで、$s^T_{n,t} = S^T_{n,t}/\tau$ は教師モデルの温度スケーリング後のスコア、$s^S_{n,t} = S^S_{n,t}/\tau$ は生徒モデルの温度スケーリング後のスコアを表す。$L$ はインスタンス $n$ のトークン長を表す。この正規化により、$\sum_{t=1}^{L} p^T_{n,t} = 1$ かつ $\sum_{t=1}^{L} p^S_{n,t} = 1$ を満たす確率分布が得られ、教師モデルと生徒モデルの重要度分布を比較できるようになる。

\clearpage
\section{重要度分布の最小化}
前節で作成した教師モデルと生徒モデルの重要度分布の類似度を測定し、その類似度を最大化するように生徒モデルを学習させる。本研究では、2つの分布の類似度を測る指標としてJaccard係数を用いる。Jaccard係数は、2つの集合の類似度を測る指標であり、2つの集合の共通部分の大きさを和集合の大きさで割った値として定義される：

\begin{equation}
J(A, B) = \frac{|A \cap B|}{|A \cup B|}
\label{eq:jaccard}
\end{equation}

ここで、$A$ と $B$ はそれぞれ2つの集合を表す。Jaccard係数は $0$ から $1$ の値をとり、2つの集合が完全に一致する場合に $1$、共通部分が存在しない場合に $0$ となる。

しかしながら、従来のJaccard係数は離散的な集合に対して定義される指標である。本研究では、生徒モデルの学習において、損失関数を最小化するようにパラメータを更新する必要があり、そのためには損失関数が生徒モデルのパラメータに関して微分可能でなければならない。従来のJaccard係数は微分不可能であるため、勾配降下法によるパラメータ更新に用いることができない。

そこで、微分可能なSoft Jaccard Similarity\cite{wang2024jaccardmetriclossesoptimizing}を用いる。Soft Jaccard Similarityは、従来のJaccard係数を連続的な確率分布に拡張したものであり、以下のように定義される。

\begin{equation}
J_{\text{soft}}(\mathbf{p}^T, \mathbf{p}^S) = \frac{\sum_{t=1}^{L} p^T_{n,t} \cdot p^S_{n,t}}{\sum_{t=1}^{L} (p^T_{n,t})^2 + \sum_{t=1}^{L} (p^S_{n,t})^2 - \sum_{t=1}^{L} p^T_{n,t} \cdot p^S_{n,t}}
\label{eq:soft_jaccard}
\end{equation}

ここで、$\mathbf{p}^T$ は教師モデルの重要度分布、$\mathbf{p}^S$ は生徒モデルの重要度分布を表す。分子は2つの分布の内積であり、従来のJaccard係数における積集合に相当する。分母は2つの分布の自乗和の和から内積を引いたものであり、和集合に相当する。Soft Jaccard Similarityは確率分布に対して連続的に定義されるため微分可能であり、損失関数として用いて勾配降下法により生徒モデルのパラメータを更新することが可能になる。

\section{本研究で提案する最終的な蒸留損失項}
本研究では、今までに述べた重要度分布の類似度を最大化する損失項を、知識蒸留における生徒モデルの最終的な損失関数に追加する。具体的には、以下のように定義される。

\begin{equation}
\mathcal{L}_{\mathrm{SJ}}
= 1 - J_{\text{soft}}(\mathbf{p}^T, \mathbf{p}^S)
\label{eq:sj_loss}
\end{equation}

ここで、$\mathcal{L}_{\mathrm{SJ}}$ は本研究で提案する蒸留損失項を表す。$J_{\text{soft}}(\mathbf{p}^T, \mathbf{p}^S)$ は式\eqref{eq:soft_jaccard}で定義されるSoft Jaccard Similarityであり、教師モデルと生徒モデルの重要度分布の類似度を $[0,1]$ の範囲で評価する指標である。値が大きいほど両者の注目パターンが一致していることを意味する。

本研究では、類似度の最大化を目的とする代わりに、最小化問題として扱うために損失項を $1-J_{\text{soft}}$ の形で定義している。これにより、完全一致の場合は $\mathcal{L}_{\mathrm{SJ}}=0$ となり，類似性が低い場合ほど損失が大きくなるという直観的な対応が得られる。本研究で提案は他の知識蒸留手法に組み込むことを想定しているため、交差エントロピー損失や既存の損失関数に加算する形で用いるため、最小化問題として扱うことは、他の損失関数と整合的に組み合わせることができる。



\clearpage
\section{提案手法を用いた生徒モデルの学習}
本章では、提案する蒸留損失項を用いた生徒モデルの学習方法について述べる。本研究においては、GLUEの各タスクにおいてファインチューニングされたBERTを教師として知識蒸留されたTinyBERTに対して、提案手法を適用する。

\subsection{ベースライン}
ベースラインとして利用するTinyBERTはファインチューニングについて2段階の蒸留を行う。第1段階では中間層の隠れ状態について生徒の内部表現を教師に近づける。第2段階では教師の出力と学習データのラベルを併用して生徒の出力層を学習させる。本研究ではEncoderブロックを6層および4層の2種類を採用する。精度を表\ref{tab:tinybert_performance}に示す。
\begin{table}[H]
\centering
\small
\caption{TinyBERTのGLUEでの精度}
\label{tab:tinybert_performance}
\makebox[\textwidth][c]{%
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|r|r|r|r|r|r|r|r|}
\hline
Model & MRPC & CoLA & STS-B & RTE & QQP & MNLI & QNLI & SST-2 \\
Metric & acc & mcc & pearson & acc & acc & acc (m/mm) & acc & acc \\
\hline
BERT-base (FineTuned) & 88.24 & 53.39 & 87.95 & 72.92 & 90.88 & 83.9/83.4 & 91.45 & 92.43 \\
\hline
TinyBERT-6L & 86.27 & 48.72 & 87.70 & 63.90 & 90.87 & 83.94 & 90.33 & 91.74 \\
\hline
TinyBERT-4L & 85.54 & 37.48 & 87.41 & 63.18 & 90.12 & 81.80 & 87.06 & 90.94 \\
\hline
\end{tabular}%
}%
}
\end{table}

\subsection{学習タスク}
本研究では、GLUEタスクに含まれるデータを対象とする。GLUEは自然言語理解の多様な側面を評価するために設計されたベンチマークであり、具体的なタスクの詳細を述べる。

\begin{description}
	\setlength{\itemsep}{0.4\baselineskip}
	\item[CoLA] 文の文法的妥当性判定。与えられた文が文法的に自然（acceptable）か否かを判定する二値分類タスク
	\item[SST-2] 文の感情判定（感情分析）。短いレビュー文が肯定的か否定的かを判定する二値分類タスク
	\item[MRPC] パラフレーズ判定。2つの文が意味的に同義（paraphrase）かどうかを判定する二値分類タスク
	\item[STS-B] 文対の意味的類似度評価。2文の意味的類似度を連続値（0--5）で評価する回帰タスク
	\item[QQP] 質問ペアの重複判定。Quora上の2つの質問が同じ意図・内容かを判定する二値分類タスク
	\item[MNLI] 自然言語推論 (Multi-Genre NLI)。前提と仮説の関係が含意（entailment）、矛盾（contradiction）、中立（neutral）のいずれかを判定する三値分類タスク
	\item[QNLI] 質問と文の関連判定。与えられた文が質問に対する答えや関連情報を含むかどうかを判定する二値分類タスク
	\item[RTE] テキスト含意判定タスク。前提と仮説の含意関係（含意／非含意）を判定する二値分類タスク
\end{description}

\begin{table}[H]
\centering
\small
\caption{本研究で用いるGLUEタスクの例とラベル}
\label{tab:glue_examples}
\begin{tabularx}{\textwidth}{|l|X|c|}
\hline
タスク & 入力例 & ラベル \\
\hline
CoLA & ``He go to the store.'' & unacceptable \\
\hline
SST-2 & ``The movie was fantastic and deeply moving.'' & positive  \\
\hline
MRPC & \begin{tabular}[t]{@{}l@{}}``The company reported profits.''\\ ``The firm announced earnings.''\end{tabular} & equivalent \\
\hline
STS-B & \begin{tabular}[t]{@{}l@{}}``A man is playing a guitar.''\\ ``Someone plays a stringed instrument.''\end{tabular} & 4.5 \\
\hline
QQP & \begin{tabular}[t]{@{}l@{}}``How to bake a cake?''\\ ``What is the process to make a cake?''\end{tabular} & duplicate \\
\hline
MNLI & \begin{tabular}[t]{@{}l@{}}前提: ``A dog is sleeping on the couch.''\\ 仮説: ``An animal is resting on furniture.''\end{tabular} & entailment \\
\hline
QNLI & \begin{tabular}[t]{@{}l@{}}質問: ``Who wrote Hamlet?''\\ 文: ``Hamlet was written by Shakespeare.''\end{tabular} & relevant / entailment \\
\hline
RTE & \begin{tabular}[t]{@{}l@{}}前提: ``The sky is clear and blue.''\\ 仮説: ``The sky has no color.''\end{tabular} & not-entailed \\
\hline
\end{tabularx}
\end{table}
\begin{table}[H]
\centering
\caption{各タスクにおけるデータ拡張と学習データ量}
\label{tab:data_augmentation_ratio}
\begin{tabular}{|l|r|r|r|}
\hline
タスク & オリジナル学習データ量 & ランダムサンプリングの有無 & 学習データ量 \\
\hline
MRPC & 3,669 & 無 & 225,098 \\
\hline
CoLA & 8,552 & 無 & 211,059 \\
\hline
STS-B & 5,750 & 無 & 320,113 \\
\hline
RTE & 2,491 & 無 & 68,796 \\
\hline
QQP & 363,847 & 有 & 1,221,763  \\
\hline
MNLI & 392,703 & 有 & 1,091,538 \\
\hline
QNLI & 104,744 & 無 & 1,250,571 \\
\hline
SST-2 & 67,350 & 無 & 1,107,510 \\
\hline
\end{tabular}
\end{table}

学習データに関して、TinyBERTTでの公式拡張データ量はQQPが7,572,066件、MNLIが8,094,053件に拡張されている。拡張は、オリジナルの学習データからある単語をランダムにマスクし、BERTで予測した単語で置換することで行われる。タスクによって拡張率は異なるが、オリジナルの学習データ1インスタンスにつき複数の拡張データが生成されるため、拡張後のデータ量は大幅に増加する。QQPとMNLIに関しては他のタスクよりも圧倒的にデータ量が増大しており、本研究の計算量では膨大な時間を要した。よって、QQPとMNLIに関しては、同じオリジナルの学習データから生成された拡張データ群からランダムに一定量のデータ数を均等にランダムサンプリングすることで適切な学習時間とデータの偏りを無くした。

\subsection{損失関数の定義}
本研究の実験では、TinyBERTの実装をベースに提案手法である蒸留項を導入し、蒸留をすることでTinyBERTの精度を維持しつつ、教師モデルと同じ単語に着目して推論を行うことを目指す。TinyBERTの学習は2段階で行われ、第1段階で中間層の隠れ状態やAttention重みを教師モデルから模倣したモデルを用意する。本研究では、第2段階で出力層を教師から模倣する段階に介入する。

第2段階では、予測層蒸留損失 $\mathcal{L}_{\mathrm{pred}}$ が用いられる。$\mathcal{L}_{\mathrm{pred}}$ は、教師モデルのロジット（ソフトラベル）と生徒モデルのロジットの間の交差エントロピーであり、次式で定義される。

\begin{equation}
\mathcal{L}_{\mathrm{pred}} = \mathrm{CE}(\mathbf{z}^T/t, \mathbf{z}^S/t)
\label{eq:pred_tinybert}
\end{equation}

ここで、$\mathbf{z}^S$ と $\mathbf{z}^T$ はそれぞれ生徒モデルと教師モデルが予測するロジット、$\mathrm{CE}$ はクロスエントロピー損失、$t$ は温度パラメータを表す。TinyBERTの実験では $t=1$ が有効であると報告されており、本研究でも同様に設定する。

\clearpage
本研究では、提案する蒸留損失項をTinyBERTの予測層蒸留損失に加算する形で最終的な損失関数を定義する。最終的な損失関数は以下のように表される。

\begin{equation}
\mathcal{L} = \mathcal{L}_{\mathrm{pred}} + \lambda \mathcal{L}_{\mathrm{SJ}}
\label{eq:final_loss}
\end{equation}

ここで、$\lambda$は提案する蒸留損失項の重みを制御するハイパーパラメータである。$\lambda$ の値を調整することで、予測精度と注目パターンの一致度のトレードオフを制御できる。本研究では、各タスクにおいて $\lambda$ の値をいくつか試し、タスクによって最適な値を選択した。また、本研究における積分ステップ数は20とした。



\chapter{評価}
\section{概要}
本章では、提案手法の有効性を評価するための実験設定と結果について述べる。提案手法を用いて学習した生徒モデルが、教師モデルと同様の単語に注目して推論を行うかどうかを評価するために、Jaccard係数およびRanking指標を用いる。

Jaccard係数は、教師モデルと生徒モデルが注目する単語の重なり具合を測定する指標であり、Top-Kの単語に対して計算される。集合の共通部分を評価するため、順位は考慮されない。例えば、教師モデルのTop-2の単語が生徒モデルではTop-1となり順位が入れ替わっていても、どちらも上位K個に含まれていれば一致とみなされる。

Ranking指標は、教師モデルと生徒モデルの重要度スコアの順位の一致度を測定する指標であり、Top-1からTop-Kまでの順位を逐次的に比較する。各K（K=1,2,...10）において1位から順番通りに完全に一致している必要があるため、Jaccard係数よりも厳密な評価が可能である。

評価については、訓練データには含まれていない検証セットを用いた。タスクごとの検証セットのインスタンス数を以下のテーブルに示す。

\begin{table}[H]
\centering
\small
\caption{評価セットのインスタンス数}
\label{tab:eval_set_sizes}
\begin{tabular}{|l|l|r|}
\hline
Task & Split & Instances \\
\hline
CoLA & dev & 1043 \\
MNLI & dev\_matched & 9815 \\
MNLI & dev\_mismatched & 9832 \\
MRPC & dev & 408 \\
QNLI & dev & 5463 \\
QQP & dev & 40430 \\
RTE & dev & 277 \\
SST-2 & dev & 872 \\
STS-B & dev & 1500 \\
WNLI & dev & 71 \\
\hline
\end{tabular}
\end{table}



\section{学習によるモデル精度}
本研究では、推論根拠の一致を優先しつつも、分類精度への影響を最小限に抑えることを目指した。表\ref{tab:proposed_performance}に、提案手法を適用したモデルとベースラインとの精度比較を示す。


\begin{table}[H]
\centering
\small
\caption{提案手法を適用したモデルの精度}
\label{tab:proposed_performance}
\makebox[\textwidth][c]{%
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|r|r|r|r|r|r|r|r|}
\hline
Model & MRPC & CoLA & STS-B & RTE & QQP & MNLI(m/mm) & QNLI & SST-2 \\
Metric & acc & mcc & pearson & acc & acc & acc & acc & acc \\
\hline
BERT-base(FineTuned) & 88.2446 & 53.3926 & 87.9523 & 72.9221 & 90.8831 & 83.9124/83.4624 & 91.4531 & 92.4331 \\
\hline
TinyBERT-6L & 86.2745 & 48.7236 & 87.7010 & 63.8989 & 90.8731 & 83.9429 & 90.3350 & 91.7431 \\
TinyBERT-4L & 85.5392 & 37.4795 & 87.4071 & 63.1769 & 90.1237 & 81.8034 & 87.0584 & 90.9404 \\
\hline
TinyBERT-6L\_IGLoss & 86.7647 & 47.9843 & 87.5443 & 66.065 & 88.7789 & 82.9462 & 89.8875 & 90.8964 \\
TinyBERT-4L\_IGLoss & 85.7843 & 38.3231 & 86.9364 & 67.509 & 89.0041 & 81.1528 & 87.4531 & 90.8963 \\
\hline
\end{tabular}%
}%
}
\end{table}
提案損失の導入によって、分類精度を大きく損なうことなく、タスクによっては改善をもたらす一方、いくつかのタスクでは小幅な低下も観察された。TinyBERT-6Lでは、MRPC、RTEが向上し、特にRTEで効果が顕著である。
一方、CoLA、STS-B、QQP、MNLI、QNLI、SST-2ではわずかな低下が見られた。
TinyBERT-4Lでは、RTEが大幅に精度を向上させ、CoLA、MRPC、QNLIでも精度の向上が確認できた。


\section{Jaccard係数による評価}
本説では、提案手法の評価の1つ目として、Jaccard係数による評価結果を示す。具体的には、GLUEの各タスクの評価セットについて教師モデルの推論根拠となる単語を記録し、提案手法を適用した生徒モデルが同じ単語に注目しているかどうかをJaccard係数で評価する。例えば、データセットの中のあるインスタンスでは教師モデルは以下のテーブルのような注目単語を持っているとする。

\begin{table}[H]
\centering
\small
\caption{教師モデルの注目単語の例（Ranking指標）}
\label{tab:teacher_example_ranking}
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|}
\hline
Top-1 & Top-2 & Top-3 & Top-4 & Top-5 & Top-6 & Top-7 & Top-8 & Top-9 & Top-10 \\
\hline
weird & distanced & and & seem & . & but & really & too & yet & ! \\
\hline
\end{tabular}
\end{table}	

同じインスタンスに対して、生徒モデルは以下のような注目単語を持っているとする。
\begin{table}[H]
\centering
\small
\caption{生徒モデルの注目単語の例（Ranking指標）}
\label{tab:student_example_ranking}
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|}
\hline
Top-1 & Top-2 & Top-3 & Top-4 & Top-5 & Top-6 & Top-7 & Top-8 & Top-9 & Top-10 \\
\hline
seem & and & distanced & weird & . & really & but & yet & too & ! \\
\hline
\end{tabular}
\end{table}	

この例の場合、Top-1からTop-10までのJaccard係数を計算すると、以下のようになる。

\begin{table}[H]
\centering
\small
\caption{Jaccard係数の評価例}
\label{tab:jaccard_example}
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|}
\hline
Top-1 & Top-2 & Top-3 & Top-4 & Top-5 & Top-6 & Top-7 & Top-8 & Top-9 & Top-10 \\
\hline
0.000 & 0.333 & 0.500 & 1.000 & 0.667 & 0.714 & 0.750 & 0.778 & 1.000 & 1.000 \\
\hline
\end{tabular}
\end{table}	

本評価では、GLUEの各タスクにおいて、提案手法を適用し蒸留したTinyBERTと、公式設定で蒸留したTinyBERTのJaccard係数を比較する。評価セットに含まれる全インスタンスについて、Top-1からTop-10までのJaccard係数を計算し、その平均値を報告する。




\subsection{ベースラインモデルのJaccard係数}
ベースラインとして採用しているTinyBERT-6LおよびTinyBERT-4Lの各タスクにおけるTop-K Jaccard係数を表\ref{tab:topk_baseline_6L}および表\ref{tab:topk_baseline_4L}に示す。

\begin{table}[H]
\centering
\small
\caption{TinyBERT-6LのTop-K Jaccard係数}
\label{tab:topk_baseline_6L}
\makebox[\textwidth][c]{%
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|r|r|r|r|r|r|r|r|r|r|}
\hline
Task & Top-1 & Top-2 & Top-3 & Top-4 & Top-5 & Top-6 & Top-7 & Top-8 & Top-9 & Top-10 \\
\hline
CoLA & 0.498 & 0.497 & 0.566 & 0.647 & 0.729 & 0.782 & 0.821 & 0.857 & 0.877 & 0.883 \\
MNLI & 0.356 & 0.357 & 0.369 & 0.393 & 0.416 & 0.437 & 0.458 & 0.480 & 0.501 & 0.520 \\
MRPC & 0.132 & 0.136 & 0.153 & 0.174 & 0.196 & 0.219 & 0.239 & 0.267 & 0.288 & 0.306 \\
QNLI & 0.288 & 0.267 & 0.279 & 0.296 & 0.314 & 0.334 & 0.350 & 0.367 & 0.382 & 0.400 \\
QQP & 0.212 & 0.234 & 0.275 & 0.309 & 0.347 & 0.375 & 0.403 & 0.430 & 0.458 & 0.489 \\
RTE & 0.133 & 0.196 & 0.229 & 0.260 & 0.283 & 0.296 & 0.318 & 0.348 & 0.372 & 0.382 \\
SST-2 & 0.365 & 0.335 & 0.333 & 0.359 & 0.389 & 0.416 & 0.445 & 0.472 & 0.503 & 0.530 \\
STS-B & 0.171 & 0.195 & 0.240 & 0.283 & 0.329 & 0.373 & 0.411 & 0.448 & 0.483 & 0.519 \\
\hline
\end{tabular}%
}%
}
\end{table}

\begin{table}[H]
\centering
\small
\caption{TinyBERT-4LのTop-K Jaccard係数}
\label{tab:topk_baseline_4L}
\makebox[\textwidth][c]{%
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|r|r|r|r|r|r|r|r|r|r|}
\hline
Task & Top-1 & Top-2 & Top-3 & Top-4 & Top-5 & Top-6 & Top-7 & Top-8 & Top-9 & Top-10 \\
\hline
CoLA & 0.410 & 0.436 & 0.508 & 0.599 & 0.691 & 0.762 & 0.801 & 0.834 & 0.858 & 0.863 \\
MNLI & 0.341 & 0.355 & 0.382 & 0.412 & 0.442 & 0.470 & 0.494 & 0.518 & 0.540 & 0.560 \\
MRPC & 0.145 & 0.174 & 0.205 & 0.233 & 0.268 & 0.299 & 0.322 & 0.347 & 0.364 & 0.386 \\
QNLI & 0.245 & 0.233 & 0.247 & 0.267 & 0.289 & 0.311 & 0.329 & 0.347 & 0.365 & 0.383 \\
QQP & 0.212 & 0.238 & 0.277 & 0.315 & 0.349 & 0.377 & 0.403 & 0.428 & 0.454 & 0.481 \\
RTE & 0.162 & 0.222 & 0.266 & 0.286 & 0.306 & 0.335 & 0.356 & 0.386 & 0.410 & 0.422 \\
SST-2 & 0.388 & 0.356 & 0.370 & 0.406 & 0.446 & 0.475 & 0.501 & 0.530 & 0.557 & 0.586 \\
STS-B & 0.191 & 0.228 & 0.275 & 0.314 & 0.360 & 0.408 & 0.453 & 0.503 & 0.548 & 0.585 \\
\hline
\end{tabular}%
}%
}
\end{table}

\subsection{提案手法で学習したモデルのJaccard係数}
提案手法を適用して学習したTinyBERT-6LおよびTinyBERT-4Lの各タスクにおけるTop-K Jaccard係数を表\ref{tab:topk_proposed_6L}および表\ref{tab:topk_proposed_4L}に示す。

\begin{table}[H]
\centering
\small
\caption{TinyBERT-6LのTop-K Jaccard係数（提案手法）}
\label{tab:topk_proposed_6L}
\makebox[\textwidth][c]{%
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|r|r|r|r|r|r|r|r|r|r|}
\hline
Task & Top-1 & Top-2 & Top-3 & Top-4 & Top-5 & Top-6 & Top-7 & Top-8 & Top-9 & Top-10 \\
\hline
CoLA & 0.682 & 0.641 & 0.671 & 0.727 & 0.783 & 0.822 & 0.858 & 0.883 & 0.897 & 0.898 \\
MNLI & 0.426 & 0.434 & 0.460 & 0.490 & 0.515 & 0.540 & 0.565 & 0.586 & 0.608 & 0.626 \\
MRPC & 0.203 & 0.223 & 0.246 & 0.268 & 0.294 & 0.330 & 0.355 & 0.375 & 0.396 & 0.414 \\
QNLI & 0.327 & 0.303 & 0.321 & 0.339 & 0.360 & 0.379 & 0.397 & 0.414 & 0.433 & 0.451 \\
QQP & 0.439 & 0.461 & 0.494 & 0.527 & 0.555 & 0.579 & 0.597 & 0.616 & 0.635 & 0.658 \\
RTE & 0.199 & 0.230 & 0.264 & 0.295 & 0.325 & 0.343 & 0.364 & 0.387 & 0.414 & 0.432 \\
SST-2 & 0.587 & 0.557 & 0.573 & 0.601 & 0.617 & 0.642 & 0.665 & 0.688 & 0.708 & 0.731 \\
STS-B & 0.311 & 0.327 & 0.365 & 0.417 & 0.466 & 0.508 & 0.554 & 0.597 & 0.633 & 0.665 \\
\hline
\end{tabular}%
}%
}
\end{table}

\begin{table}[H]
\centering
\small
\caption{TinyBERT-4LのTop-K Jaccard係数（提案手法）}
\label{tab:topk_proposed_4L}
\makebox[\textwidth][c]{%
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|r|r|r|r|r|r|r|r|r|r|}
\hline
Task & Top-1 & Top-2 & Top-3 & Top-4 & Top-5 & Top-6 & Top-7 & Top-8 & Top-9 & Top-10 \\
\hline
CoLA & 0.651 & 0.602 & 0.624 & 0.686 & 0.735 & 0.774 & 0.814 & 0.849 & 0.871 & 0.881 \\
MNLI & 0.450 & 0.453 & 0.481 & 0.508 & 0.534 & 0.560 & 0.581 & 0.601 & 0.619 & 0.636 \\
MRPC & 0.270 & 0.296 & 0.306 & 0.329 & 0.352 & 0.381 & 0.404 & 0.429 & 0.450 & 0.473 \\
QNLI & 0.331 & 0.322 & 0.332 & 0.355 & 0.379 & 0.399 & 0.418 & 0.436 & 0.452 & 0.468 \\
QQP & 0.406 & 0.435 & 0.471 & 0.508 & 0.537 & 0.561 & 0.579 & 0.597 & 0.615 & 0.635 \\
RTE & 0.260 & 0.304 & 0.335 & 0.381 & 0.388 & 0.415 & 0.439 & 0.447 & 0.478 & 0.491 \\
SST-2 & 0.572 & 0.518 & 0.560 & 0.571 & 0.599 & 0.624 & 0.649 & 0.679 & 0.692 & 0.710 \\
STS-B & 0.265 & 0.291 & 0.337 & 0.390 & 0.438 & 0.482 & 0.526 & 0.567 & 0.607 & 0.641 \\
\hline
\end{tabular}%
}%
}
\end{table}
また、提案手法におけるjaccard係数の各タスクごとのTop-Kの結果を図\ref{fig:topk_jaccard_6L}および図\ref{fig:topk_jaccard_4L}に示す。


\begin{figure}[H]
\centering
\caption{提案手法による各タスクの改善（TinyBERT-6L）}
\label{fig:topk_jaccard_6L}
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/jaccard/CoLA/CoLA_6L_Comparison_jaccard_comparison.png}
\end{minipage}
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/jaccard/MNLI/MNLI_6L_Comparison_jaccard_comparison.png}
\end{minipage}\\[0.6em]
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/jaccard/MRPC/MRPC_6L_Comparison_jaccard_comparison.png}
\end{minipage}
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/jaccard/QNLI/QNLI_6L_Comparison_jaccard_comparison.png}
\end{minipage}\\[0.6em]
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/jaccard/QQP/QQP_6L_Comparison_jaccard_comparison.png}
\end{minipage}
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/jaccard/RTE/RTE_6L_Comparison_jaccard_comparison.png}
\end{minipage}\\[0.6em]
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/jaccard/SST-2/SST-2_6L_Comparison_jaccard_comparison.png}
\end{minipage}
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/jaccard/STS-B/STS-B_6L_Comparison_jaccard_comparison.png}
\end{minipage}
\end{figure}

\begin{figure}[H]
\centering
\caption{提案手法による各タスクの改善（TinyBERT-4L）}
\label{fig:topk_jaccard_4L}
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/jaccard/CoLA/CoLA_4L_Comparison_jaccard_comparison.png}
\end{minipage}
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/jaccard/MNLI/MNLI_4L_Comparison_jaccard_comparison.png}
\end{minipage}\\[0.6em]
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/jaccard/MRPC/MRPC_4L_Comparison_jaccard_comparison.png}
\end{minipage}
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/jaccard/QNLI/QNLI_4L_Comparison_jaccard_comparison.png}
\end{minipage}\\[0.6em]
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/jaccard/QQP/QQP_4L_Comparison_jaccard_comparison.png}
\end{minipage}
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/jaccard/RTE/RTE_4L_Comparison_jaccard_comparison.png}
\end{minipage}\\[0.6em]
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/jaccard/SST-2/SST-2_4L_Comparison_jaccard_comparison.png}
\end{minipage}
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/jaccard/STS-B/STS-B_4L_Comparison_jaccard_comparison.png}
\end{minipage}
\end{figure}


\subsection{結果と考察}
本提案による学習により、全タスクにおいてJaccard係数が向上した。特にQQPとSST-2に関して全体的に大きな改善が見られた。特にCoLAについては、元々のJaccard係数が高く、特にTop-10のような大きなKにおいては0.8程度であり十分高い数値であったものの、提案手法による改善が見られ十分高い数値のKに対しても改善をさせることができる可能性を示唆している。

今回学習したデータ量には大きなばらつきがあり、タスクによって大きな偏りがあり、MRPCやCoLA、RTEに関して、他のタスクよりもデータの量が少ないものの、これらのタスクにおいてもJaccard係数の改善が見られたことから、提案手法は学習データ量が少ない場合でも有効である可能性が示唆される。

グラフの形状を見ると、特定のTop-Kのみに集中して精度の向上が見られるのではなく、全体的に均一に精度が向上している様子が見られる。これは、提案手法の分布全体を考慮した蒸留が、特定のKに偏ることなく全体的な注目パターンの一致度を高めることに寄与していることが考えられる。

STS-Bのようなわずかな精度の低下が見られたものの、jaccard係数が大きく向上しているタスクに至っては、提案手法のハイパーパラメータを調整することで、精度の低下を抑えつつ注目パターンの一致度を高めるように調整可能であると考えられる。

\section{Rankingによる評価}
本節では、提案手法の評価の2つ目として、Ranking指標による評価結果を示す。具体的には、GLUEの各タスクの評価セットについて教師モデルの推論根拠となる単語を記録し、提案手法を適用した生徒モデルが同じ単語に注目しているかどうかをRanking指標で評価する。本指標は各Kにおいて、Top-1〜Top-Kの位置ごとの順位一致率（1..Kのうち位置が一致した割合）を用いるため、集合一致のみを見るJaccard係数よりも順序情報に対して厳密な評価が可能である。評価に利用するデータはJaccard係数の評価と同じデータセットを利用する。例えば、データセットの中のあるインスタンスでは教師モデルは以下のテーブルのような注目単語を持っているとする。

\begin{table}[H]
\centering
\small
\caption{教師モデルの注目単語の例}
\label{tab:teacher_example}
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|}
\hline
Top-1 & Top-2 & Top-3 & Top-4 & Top-5 & Top-6 & Top-7 & Top-8 & Top-9 & Top-10 \\
\hline
weird & distanced & and & seem & . & but & really & too & yet & ! \\
\hline
\end{tabular}
\end{table}	

\begin{table}[H]
\centering
\small
\caption{生徒モデルの注目単語の例}
\label{tab:student_example}
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|}
\hline
Top-1 & Top-2 & Top-3 & Top-4 & Top-5 & Top-6 & Top-7 & Top-8 & Top-9 & Top-10 \\
\hline
weird & and & distanced & seem & . & really & but & too & yet & ! \\
\hline
\end{tabular}
\end{table}	

この例の場合、Top-1からTop-10までのRanking指標を計算すると、以下のようになる。
\begin{table}[H]
\centering
\small
\caption{Ranking指標の評価例}
\label{tab:ranking_example}
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|}
\hline
Top-1 & Top-2 & Top-3 & Top-4 & Top-5 & Top-6 & Top-7 & Top-8 & Top-9 & Top-10 \\
\hline
1.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\
\hline
\end{tabular}
\end{table}	

これは、Top-1の単語が一致している一方で、Top-2からTop-9までの単語がすべて不一致であり、Top-10においては6つの単語が一致しているためである。Top-Kの時点で、Top-1からTop-10まで順番を含めた完全一致の単語が生徒モデルで選択されていることが望ましい。本評価では、GLUEの各タスクにおいて、提案手法を適用し蒸留したTinyBERTと、公式設定で蒸留したTinyBERTのRanking指標を比較する。評価セットに含まれる全インスタンスについて、Top-1からTop-10までのRanking指標を計算し、その平均値を報告する。利用するデータはJaccard係数の評価と同じデータセットを利用する。
\subsection{ベースラインモデルのRanking指標}
ベースラインとして採用しているTinyBERT-6LおよびTinyBERT-4Lの各タスクにおけるTop-K Ranking指標を表\ref{tab:topk_ranking_baseline_6L}および表\ref{tab:topk_ranking_baseline_4L}に示す。

\begin{table}[H]
\centering
\small
\caption{TinyBERT-6LのTop-K Ranking指標}
\label{tab:topk_ranking_baseline_6L}
\makebox[\textwidth][c]{%
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|r|r|r|r|r|r|r|r|r|r|}
\hline
Task & Top-1 & Top-2 & Top-3 & Top-4 & Top-5 & Top-6 & Top-7 & Top-8 & Top-9 & Top-10 \\
\hline
CoLA & 0.498 & 0.216 & 0.118 & 0.081 & 0.070 & 0.066 & 0.065 & 0.065 & 0.065 & 0.065 \\
MNLI & 0.338 & 0.122 & 0.039 & 0.015 & 0.006 & 0.003 & 0.003 & 0.002 & 0.002 & 0.002 \\
MRPC & 0.118 & 0.032 & 0.012 & 0.005 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\
QNLI & 0.288 & 0.064 & 0.014 & 0.002 & 0.001 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\
QQP & 0.212 & 0.108 & 0.039 & 0.023 & 0.008 & 0.004 & 0.001 & 0.000 & 0.000 & 0.000 \\
RTE & 0.134 & 0.051 & 0.011 & 0.004 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\
SST-2 & 0.365 & 0.091 & 0.022 & 0.008 & 0.005 & 0.003 & 0.003 & 0.003 & 0.003 & 0.003 \\
STS-B & 0.171 & 0.065 & 0.022 & 0.009 & 0.002 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\
\hline
\end{tabular}%
}%
}
\end{table}	

\begin{table}[H]
\centering
\small
\caption{TinyBERT-4LのTop-K Ranking指標}
\label{tab:topk_ranking_baseline_4L}
\makebox[\textwidth][c]{%
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|r|r|r|r|r|r|r|r|r|r|}
\hline
Task & Top-1 & Top-2 & Top-3 & Top-4 & Top-5 & Top-6 & Top-7 & Top-8 & Top-9 & Top-10 \\
\hline
CoLA & 0.410 & 0.152 & 0.069 & 0.042 & 0.030 & 0.028 & 0.028 & 0.028 & 0.028 & 0.028 \\
MNLI & 0.341 & 0.113 & 0.039 & 0.015 & 0.007 & 0.003 & 0.002 & 0.001 & 0.001 & 0.001 \\
MRPC & 0.145 & 0.039 & 0.002 & 0.002 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\
QNLI & 0.245 & 0.046 & 0.007 & 0.002 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\
QQP & 0.212 & 0.086 & 0.029 & 0.014 & 0.005 & 0.002 & 0.000 & 0.000 & 0.000 & 0.000 \\
RTE & 0.162 & 0.043 & 0.018 & 0.007 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\
SST-2 & 0.388 & 0.110 & 0.041 & 0.016 & 0.009 & 0.008 & 0.008 & 0.007 & 0.007 & 0.007 \\
STS-B & 0.191 & 0.079 & 0.022 & 0.012 & 0.005 & 0.001 & 0.000 & 0.000 & 0.000 & 0.000 \\
\hline
\end{tabular}%
}%
}
\end{table}


\subsection{提案手法で学習したモデルのRanking指標}
提案手法を適用して学習したTinyBERT-6LおよびTinyBERT-4Lの各タスクにおけるTop-K Ranking指標を表\ref{tab:topk_ranking_proposed_6L}および表\ref{tab:topk_ranking_proposed_4L}に示す。

\begin{table}[H]
\centering
\small
\caption{TinyBERT-6LのTop-K Ranking指標（提案手法）}
\label{tab:topk_ranking_proposed_6L}
\makebox[\textwidth][c]{%
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|r|r|r|r|r|r|r|r|r|r|}
\hline
Task & Top-1 & Top-2 & Top-3 & Top-4 & Top-5 & Top-6 & Top-7 & Top-8 & Top-9 & Top-10 \\
\hline
CoLA & 0.682 & 0.273 & 0.130 & 0.089 & 0.075 & 0.070 & 0.068 & 0.067 & 0.067 & 0.067 \\
MNLI & 0.426 & 0.150 & 0.049 & 0.019 & 0.008 & 0.004 & 0.003 & 0.002 & 0.002 & 0.002 \\
MRPC & 0.203 & 0.055 & 0.018 & 0.007 & 0.002 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\
QNLI & 0.327 & 0.075 & 0.020 & 0.005 & 0.002 & 0.001 & 0.000 & 0.000 & 0.000 & 0.000 \\
QQP & 0.439 & 0.180 & 0.065 & 0.035 & 0.013 & 0.006 & 0.003 & 0.001 & 0.000 & 0.000 \\
RTE & 0.199 & 0.070 & 0.022 & 0.009 & 0.002 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\
SST-2 & 0.587	& 0.150 & 0.045 & 0.017 & 0.010 & 0.007 & 0.006 & 0.005 & 0.005 & 0.005 \\
STS-B & 0.311 & 0.110 & 0.035 & 0.015 & 0.004 & 0.001 & 0.000 & 0.000 & 0.000 & 0.000 \\
\hline
\end{tabular}%
}%
}
\end{table}

\begin{table}[H]
\centering
\small
\caption{TinyBERT-4LのTop-K Ranking指標（提案手法）}
\label{tab:topk_ranking_proposed_4L}
\makebox[\textwidth][c]{%
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|r|r|r|r|r|r|r|r|r|r|}
\hline
Task & Top-1 & Top-2 & Top-3 & Top-4 & Top-5 & Top-6 & Top-7 & Top-8 & Top-9 & Top-10 \\
\hline
CoLA & 0.651 & 0.240 & 0.110 & 0.072 & 0.056 & 0.049 & 0.046 & 0.045 & 0.044 & 0.044 \\
MNLI & 0.450 & 0.160 & 0.053 & 0.021 & 0.009 & 0.004 & 0.003 & 0.002 & 0.002 & 0.002 \\
MRPC & 0.270 & 0.070 & 0.025 & 0.010 & 0.003 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\
QNLI & 0.331 & 0.070 & 0.018 & 0.006 & 0.002 & 0.001 & 0.000 & 0.000 & 0.000 & 0.000 \\
QQP & 0.406 & 0.160 & 0.055 & 0.030 & 0.011 & 0.005 & 0.002 & 0.001 & 0.000 & 0.000 \\
RTE & 0.260 & 0.080 & 0.030 & 0.012 & 0.003 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\
SST-2 & 0.572 & 0.140 & 0.050 & 0.019 & 0.011 & 0.008 & 0.007 & 0.006 & 0.006 & 0.006 \\
STS-B & 0.265 & 0.090 & 0.030 & 0.013 & 0.004 & 0.001 & 0.000 & 0.000 & 0.000 & 0.000 \\
\hline
\end{tabular}%
}%
}
\end{table}	

また、提案手法で学習したモデルのRanking指標の各タスクごとのTop-Kの結果を図\ref{fig:topk_ranking_6L}および図\ref{fig:topk_ranking_4L}に可視化する。

\begin{figure}[H]
\centering
\caption{提案手法によるRanking指標の改善（TinyBERT-6L）}
\label{fig:topk_ranking_6L}
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/ranking/CoLA/CoLA_6L_Ranking_Comparison_ranking_log_styled.png}
\end{minipage}
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/ranking/MNLI/MNLI_6L_Ranking_Comparison_ranking_log_styled.png}
\end{minipage}\\[0.6em]
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/ranking/MRPC/MRPC_6L_Ranking_Comparison_ranking_log_styled.png}
\end{minipage}
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/ranking/QNLI/QNLI_6L_Ranking_Comparison_ranking_log_styled.png}
\end{minipage}\\[0.6em]
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/ranking/QQP/QQP_6L_Ranking_Comparison_ranking_log_styled.png}
\end{minipage}
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/ranking/RTE/RTE_6L_Ranking_Comparison_ranking_log_styled.png}
\end{minipage}\\[0.6em]
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/ranking/SST-2/SST-2_6L_Ranking_Comparison_ranking_log_styled.png}
\end{minipage}
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/ranking/STS-B/STS-B_6L_Ranking_Comparison_ranking_log_styled.png}
\end{minipage}
\end{figure}

\begin{figure}[H]
\centering
\caption{提案手法によるRanking指標の改善（TinyBERT-4L）}
\label{fig:topk_ranking_4L}
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/ranking/CoLA/CoLA_4L_Ranking_Comparison_ranking_log_styled.png}
\end{minipage}
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/ranking/MNLI/MNLI_4L_Ranking_Comparison_ranking_log_styled.png}
\end{minipage}\\[0.6em]
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/ranking/MRPC/MRPC_4L_Ranking_Comparison_ranking_log_styled.png}
\end{minipage}
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/ranking/QNLI/QNLI_4L_Ranking_Comparison_ranking_log_styled.png}
\end{minipage}\\[0.6em]
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/ranking/QQP/QQP_4L_Ranking_Comparison_ranking_log_styled.png}
\end{minipage}
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/ranking/RTE/RTE_4L_Ranking_Comparison_ranking_log_styled.png}
\end{minipage}\\[0.6em]
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/ranking/SST-2/SST-2_4L_Ranking_Comparison_ranking_log_styled.png}
\end{minipage}
\begin{minipage}[t]{0.49\textwidth}
	\centering
	\includegraphics[width=\textwidth]{data/experiment_figure/figure/ranking/STS-B/STS-B_4L_Ranking_Comparison_ranking_log_styled.png}
\end{minipage}
\end{figure}


\subsection{結果と考察}
Ranking指標に基づく評価結果を確認すると、全体として改善の傾向が見られた。しかし、Jaccard係数による評価とは異なり、4層モデル（4L）と6層モデル（6L）の間で改善の傾向に差異が認められた。具体的には、Jaccard係数においては、4Lと6Lでグラフの形状が類似しており、全体的に大幅な改善が見られた。これは、ベースラインモデルと比較して、提案手法を適用したモデルの評価値が全体的に底上げされ、グラフが平行移動したような形状を示していると言える。

一方で、Ranking指標においては、改善後のグラフの傾向に相違が見られた。ベースラインモデルについてはJaccard係数と同様に4Lと6Lで類似した形状を示していたものの、提案手法適用後のグラフでは、Kの値に応じた一様な改善ではなく、大きな変動が観察された。モデルの容量の違いから、6Lの方が改善度合いが大きいことが期待されたが、MRPCとRTE、QNLIの中の一部のKで悪化しているが、4Lの同じタスクに注目すると、悪化することはなくむしろ改善している様子が見られる。Jaccard係数のときは底上げされるスコアが6Lの方が大きかったのに対し、Ranking指標では4Lの方が改善が大きい傾向が見られた。一般にモデルが持つパラメタ数が多いモデルの方が表現力が大きく、教師モデルの注目パターンを模倣しやすいと考えられるが、Ranking指標においては、表現力が大きいことが必ずしも有利に働かない可能性があると考える。


\chapter{おわりに}
\section{本研究のまとめ}
本研究では、従来の知識蒸留では考慮されていなかった教師モデルから生徒モデルへの、推論時における重要単語の注目パターンの転移に着目し知識蒸留を施すことで、モデルの推論における根拠となる単語を生徒モデルに転移させるための手法を提案した。従来の手法では、教師モデルから生徒モデルへ精度のみに着目し蒸留をしたことで必ずしも推論ににおける根拠が転移されないという課題があった。本研究では、この課題に対応するためIntegrated Gradientを用いて教師モデルから得られた単語の重要度分布を生徒モデルに転移させるための新たな知識蒸留手法を提案した。提案手法では、教師モデルと生徒モデルの単語重要度分布の一致度をJaccard係数およびRanking指標で評価し、これらの指標を最大化するように生徒モデルを学習することで、推論根拠の転移を推進する新たなアプローチを提案した。

具体的には、GLUEの各タスクにおいて、教師モデルと生徒モデルに同じインスタンスを推論させた。その際、教師モデルのインスタンごとの重要単語をIntegrated Gradientを用いて算出した。トークナイザによって分割された各単語のモデルが持つ次元数の重要度ベクトルを取得し、L2ノルムを利用して各単語の重要度をスカラー値に集約させた。次に、温度付きのSoftmax関数を用いて、各単語を全体て1になるように正規化し、そのインスタンスのトークン列に対して重要度分布を得た。生徒モデルに対しても同様に重要度分布を作成し、教師モデルと生徒モデルの重要度分布の一致度を高めるように損失を設計した。Jaccard係数を最大化するように生徒モデルを学習することで、推論根拠の転移を推進する新たなアプローチを提案した。

実験では、Jaccard係数およびRanking指標としてGLUEの各タスクの評価セットにおいて、提案手法を適用した生徒モデルと、公式設定で蒸留した生徒モデルの指標を比較した。実験の結果、提案手法を適用した生徒モデルは、Jaccard係数に関しては一貫して全タスクで指標が向上した、特にMRPCとRTEに関しては、精度の向上も見られ、本提案の有効性を示した。他のタスクに関しては軽微な低下が見られたものの、Jaccard係数の一致においては本提案手法において大きな改善が見られ、一定の効果があることが示された。これらのタスクに関しては、提案手法のハイパーパラメータを調整することで、精度の低下を抑えつつ注目パターンの一致度を高めるように調整可能であると考えられる。

Ranking指標については、各タスクの一部のKにおいては低下が見られたものの、多くのKにおいては改善が見られ、全体的にはどのタスクにおいても改善が確認された。Ranking指標は生徒モデルが教師モデルとの間の順位情報を一致させなければならず、Jaccard係数よりも厳密で難しい指標であり、Top-Kが大きくなるほど一気に低下しやすい。それにもかかわらず、多くのタスクにおいて大きいKであっても微笑な改善が見られ、小さいKでは完全一致の割合が大きく向上していることから、提案手法が教師モデルと生徒モデルの注目パターンの一致度を高めることに寄与していることが示された。しかしながら、一部のタスクにおいては軽微なスコアの低下や、改善が見られなかったKも存在した。

本研究では、以下の点で貢献が挙げられる。従来では考えられてこなかった推論過程を考慮したアプローチを提案した点にある。従来の知識蒸留手法では、モデルの精度にのみ着目し、推論過程における根拠の転移を考慮してこなかった。知識蒸留では教師モデルの代替となるような小さなモデルを構築する技術である前提では、教師モデルと精度以外のあらゆる点でも機序を一致されることが望ましく、例えば、すでに十分動いているシステムでは単純に精度だけで代替できるかは疑問である。提案手法は、推論過程における根拠の転移を考慮した新たな知識蒸留手法を提案し、知識蒸留の新たな方向性を示した点で貢献がある。

\section{今後の課題}
本研究では、Integrated Gradientを持ちいた重要度分布における転移アプローチにより、精度の低下を抑えつつ蒸留するためのアプローチを提案した。一定の効果が確認されたものの、いくつかの課題が残された。

第一に、Ranking指標の向上である。本研究では、提案手法に倣い、Jaccard係数を最大化するように損失を設計したが、Ranking指標は順序情報を考慮したより厳密な指標であり、Jaccard係数の最大化が必ずしもRanking指標の最大化に寄与しなかった。人間にわかりやすく説明がしやすいモデルを構築するためには、単に注目単語の集合が一致するだけでなく、順位情報も一致させることが望ましい。今後の課題として、Ranking指標を直接最大化するような損失関数の設計が挙げられる。

第二に、ステップ数の調整にも課題が残る。従来のIntegrated Gradientのステップ数は計算時間と積分誤差の許容量のトレードオフによって決定するハイパーパラメータであり、著者の経験的な知見に基づいて決定されてきた経緯があり、本研究でも20に固定している。しかしながら、近年の研究では、Integrated Gradientsによる最適なステップ数はインスタンスごとに異なる点が指摘されており、この報告によれば、インスタンス毎に最適なステップ数は異なっており、その最適化の方法として、特定の誤差を下回るまでステップ数を増やしながら誤差を減らすアプローチが推奨されている\cite{makino2024idealnumberofstepforintegratedgradients}。本研究では、すべてのインスタンスに対して同じステップ数を利用しているが、今後の課題として、インスタンスごとに最適なステップ数を決定するアプローチを検討することが挙げられる。

% 付録
% \appendix
% \chapter{参考データ}

\bibliographystyle{jplain}
\bibliography{reference}

\end{document}
